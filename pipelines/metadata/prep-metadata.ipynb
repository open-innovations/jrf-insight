{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c713180c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T15:14:36.838536Z",
     "iopub.status.busy": "2023-09-18T15:14:36.838262Z",
     "iopub.status.idle": "2023-09-18T15:14:37.092753Z",
     "shell.execute_reply": "2023-09-18T15:14:37.092403Z"
    },
    "papermill": {
     "duration": 0.257584,
     "end_time": "2023-09-18T15:14:37.093848",
     "exception": false,
     "start_time": "2023-09-18T15:14:36.836264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e914ccdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T15:14:37.096371Z",
     "iopub.status.busy": "2023-09-18T15:14:37.096139Z",
     "iopub.status.idle": "2023-09-18T15:14:37.104187Z",
     "shell.execute_reply": "2023-09-18T15:14:37.103843Z"
    },
    "papermill": {
     "duration": 0.010055,
     "end_time": "2023-09-18T15:14:37.104919",
     "exception": false,
     "start_time": "2023-09-18T15:14:37.094864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = '../../data'\n",
    "with open('catalogue.yaml') as f:\n",
    "    files = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ee7708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T15:14:37.107182Z",
     "iopub.status.busy": "2023-09-18T15:14:37.107017Z",
     "iopub.status.idle": "2023-09-18T15:14:37.854292Z",
     "shell.execute_reply": "2023-09-18T15:14:37.853851Z"
    },
    "papermill": {
     "duration": 0.74991,
     "end_time": "2023-09-18T15:14:37.855648",
     "exception": false,
     "start_time": "2023-09-18T15:14:37.105738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "('Error loading %s', 'dwelling-stock/dwelling-stock.csv')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 41\u001b[0m, in \u001b[0;36mMetadata.load\u001b[0;34m(self, dataset_path, loader, variables, values, ignored, root_dir, id, group)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     dataset: pd\u001b[39m.\u001b[39mDataFrame \u001b[39m=\u001b[39m loader(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(root_dir, dataset_path))\n\u001b[1;32m     42\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/jrf-insight-VA15kXRI/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/jrf-insight-VA15kXRI/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/jrf-insight-VA15kXRI/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/jrf-insight-VA15kXRI/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1723\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1724\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/jrf-insight-VA15kXRI/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n",
      "File \u001b[0;32mparsers.pyx:579\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:668\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2050\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb0 in position 7: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 74\u001b[0m\n\u001b[1;32m     70\u001b[0m         result[\u001b[39m'\u001b[39m\u001b[39mdimensions\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mto_dict() \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimensions]\n\u001b[1;32m     71\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m---> 74\u001b[0m catalogue \u001b[39m=\u001b[39m [\n\u001b[1;32m     75\u001b[0m   Metadata()\u001b[39m.\u001b[39mload(f[\u001b[39m'\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m'\u001b[39m], root_dir\u001b[39m=\u001b[39mroot_dir, \u001b[39mid\u001b[39m\u001b[39m=\u001b[39mf[\u001b[39m'\u001b[39m\u001b[39mview\u001b[39m\u001b[39m'\u001b[39m], group\u001b[39m=\u001b[39mf[\u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m files\n\u001b[1;32m     76\u001b[0m ]\n",
      "Cell \u001b[0;32mIn[6], line 75\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m         result[\u001b[39m'\u001b[39m\u001b[39mdimensions\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mto_dict() \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdimensions]\n\u001b[1;32m     71\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m     74\u001b[0m catalogue \u001b[39m=\u001b[39m [\n\u001b[0;32m---> 75\u001b[0m   Metadata()\u001b[39m.\u001b[39;49mload(f[\u001b[39m'\u001b[39;49m\u001b[39mfile\u001b[39;49m\u001b[39m'\u001b[39;49m], root_dir\u001b[39m=\u001b[39;49mroot_dir, \u001b[39mid\u001b[39;49m\u001b[39m=\u001b[39;49mf[\u001b[39m'\u001b[39;49m\u001b[39mview\u001b[39;49m\u001b[39m'\u001b[39;49m], group\u001b[39m=\u001b[39;49mf[\u001b[39m'\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m files\n\u001b[1;32m     76\u001b[0m ]\n",
      "Cell \u001b[0;32mIn[6], line 43\u001b[0m, in \u001b[0;36mMetadata.load\u001b[0;34m(self, dataset_path, loader, variables, values, ignored, root_dir, id, group)\u001b[0m\n\u001b[1;32m     41\u001b[0m     dataset: pd\u001b[39m.\u001b[39mDataFrame \u001b[39m=\u001b[39m loader(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root_dir, dataset_path))\n\u001b[1;32m     42\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError loading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, dataset_path)\n\u001b[1;32m     45\u001b[0m \u001b[39m# Process variables\u001b[39;00m\n\u001b[1;32m     46\u001b[0m fact_columns \u001b[39m=\u001b[39m variables \u001b[39m+\u001b[39m values\n",
      "\u001b[0;31mException\u001b[0m: ('Error loading %s', 'dwelling-stock/dwelling-stock.csv')"
     ]
    }
   ],
   "source": [
    "def make_key(s: str, sep='-'):\n",
    "      return re.sub(r'\\W+', sep, s.lower()).strip(sep)\n",
    "\n",
    "class Dimension:\n",
    "    def __init__(self, series: pd.Series):\n",
    "        self.name = series.name\n",
    "        self.values = series.unique().tolist()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Dimension->{self.name}'\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return self.__dict__\n",
    "\n",
    "class Fact:\n",
    "    def __init__(self, series: pd.Series):\n",
    "        self.name = series.name\n",
    "        self.type = str(series.dtype)\n",
    "        self.description = series.describe().to_dict()\n",
    "        self.na = series.isna().sum()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Fact->{self.name} ({self.type})'\n",
    "\n",
    "    def to_dict(self):\n",
    "        return self.__dict__\n",
    "\n",
    "class Metadata:\n",
    "    def load(self, dataset_path: str, loader=pd.read_csv, variables=None, values=None, ignored=None, root_dir='', id=None, group=None):\n",
    "        if variables is None:\n",
    "              variables = ['variable_name']\n",
    "        if values is None:\n",
    "              values = ['value']\n",
    "        if ignored is None:\n",
    "              ignored = []\n",
    "\n",
    "        self.id = id or make_key(os.path.basename(dataset_path))\n",
    "        self.group = group or os.path.dirname(dataset_path).replace(os.sep, '.')\n",
    "\n",
    "        try:\n",
    "            dataset: pd.DataFrame = loader(os.path.join(root_dir, dataset_path))\n",
    "        except:\n",
    "            raise Exception('Error loading %s', dataset_path)\n",
    "\n",
    "        # Process variables\n",
    "        fact_columns = variables + values\n",
    "        dimension_columns = [c for c in dataset.columns.to_list() if c not in fact_columns + ignored]\n",
    "\n",
    "        # Clean up duplicates\n",
    "        dataset = dataset[~dataset.duplicated(subset=dimension_columns)]\n",
    "\n",
    "        try:\n",
    "              facts = dataset.pivot(index=dimension_columns, columns=variables, values=values).reset_index(drop=True)\n",
    "        except Exception:\n",
    "              return None\n",
    "        facts.columns = facts.columns.droplevel()\n",
    "        self.facts = [Fact(f) for _, f in facts.items()]\n",
    "\n",
    "        # Calculate dimension columns\n",
    "        self.dimensions = [Dimension(x[1]) for x in dataset.loc[:, dimension_columns].items()]\n",
    "\n",
    "        return self\n",
    "  \n",
    "    def __repr__(self):\n",
    "        return f'Metadata->{self.dimensions}->{self.facts}'\n",
    "\n",
    "    def to_dict(self):\n",
    "        result = {k: v for k, v in self.__dict__.items() if k not in ['facts', 'dimensions']}\n",
    "        result['facts'] = [f.to_dict() for f in self.facts]\n",
    "        result['dimensions'] = [d.to_dict() for d in self.dimensions]\n",
    "        return result\n",
    "\n",
    "\n",
    "catalogue = [\n",
    "  Metadata().load(f['file'], root_dir=root_dir, id=f['view'], group=f['dataset']) for f in files\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8142c13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T15:14:37.858920Z",
     "iopub.status.busy": "2023-09-18T15:14:37.858777Z",
     "iopub.status.idle": "2023-09-18T15:14:37.872584Z",
     "shell.execute_reply": "2023-09-18T15:14:37.872254Z"
    },
    "papermill": {
     "duration": 0.016663,
     "end_time": "2023-09-18T15:14:37.873710",
     "exception": false,
     "start_time": "2023-09-18T15:14:37.857047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'catalogue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m os\u001b[39m.\u001b[39mmakedirs(\u001b[39m'\u001b[39m\u001b[39m../../src/_data/metadata/\u001b[39m\u001b[39m'\u001b[39m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m output \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame([\n\u001b[0;32m----> 4\u001b[0m         entry\u001b[39m.\u001b[39mto_dict() \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m catalogue \u001b[39mif\u001b[39;00m entry\n\u001b[1;32m      5\u001b[0m ])\u001b[39m.\u001b[39mmerge(\n\u001b[1;32m      6\u001b[0m     pd\u001b[39m.\u001b[39mDataFrame(files), left_on\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mgroup\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m], right_on\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mview\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m     how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mright\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      8\u001b[0m )\u001b[39m.\u001b[39mset_index(\n\u001b[1;32m      9\u001b[0m     [\u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mview\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m )\u001b[39m.\u001b[39mdrop(\n\u001b[1;32m     11\u001b[0m     columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mgroup\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m )\u001b[39m.\u001b[39msort_values(\n\u001b[1;32m     13\u001b[0m     by\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mview\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m )\u001b[39m.\u001b[39mreset_index(\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m output\u001b[39m.\u001b[39mto_json(\n\u001b[1;32m     18\u001b[0m   \u001b[39m'\u001b[39m\u001b[39m../../src/_data/metadata/catalogue.json\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m   orient\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m   indent\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     21\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'catalogue' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs('../../src/_data/metadata/', exist_ok=True)\n",
    "\n",
    "output = pd.DataFrame([\n",
    "        entry.to_dict() for entry in catalogue if entry\n",
    "]).merge(\n",
    "    pd.DataFrame(files), left_on=['group', 'id'], right_on=['dataset', 'view'],\n",
    "    how='right'\n",
    ").set_index(\n",
    "    ['dataset', 'view']\n",
    ").drop(\n",
    "    columns=['group', 'id']\n",
    ").sort_values(\n",
    "    by=['dataset', 'view']\n",
    ").reset_index(\n",
    ")\n",
    "\n",
    "output.to_json(\n",
    "  '../../src/_data/metadata/catalogue.json',\n",
    "  orient='records',\n",
    "  indent=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ac086ed",
   "metadata": {
    "papermill": {
     "duration": 0.001205,
     "end_time": "2023-09-18T15:14:37.876196",
     "exception": false,
     "start_time": "2023-09-18T15:14:37.874991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027fefae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jrf-insight-VA15kXRI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1.978961,
   "end_time": "2023-09-18T15:14:38.093026",
   "environment_variables": {},
   "exception": null,
   "input_path": "prepare.ipynb",
   "output_path": "output/prep-metadata.ipynb",
   "parameters": {},
   "start_time": "2023-09-18T15:14:36.114065",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
