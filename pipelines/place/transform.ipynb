{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import pandas as pd\n","from geo import get_place_list, get_place_data\n","from params import DATA_DIR, SRC_DATA_DIR"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load some data\n","\n","* `all_geos` is a list of all geographies mentioned in the the geography tree csv file\n","* `population_data` is population estimates for a (some of) the geographies\n","* `council_tax_data` is estimates of people in receipt of council tax support\n","* `clif_data` is data bout children living in poverty "]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>geography_code</th>\n","      <th>geography_name</th>\n","      <th>geography_type</th>\n","      <th>gender_code</th>\n","      <th>gender_name</th>\n","      <th>age_code</th>\n","      <th>age_name</th>\n","      <th>variable_code</th>\n","      <th>variable_name</th>\n","      <th>value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>87696</th>\n","      <td>2020</td>\n","      <td>E05000026</td>\n","      <td>Abbey</td>\n","      <td>wd22</td>\n","      <td>0</td>\n","      <td>Total</td>\n","      <td>200</td>\n","      <td>All Ages</td>\n","      <td>n_persons</td>\n","      <td>Number of persons</td>\n","      <td>16149</td>\n","    </tr>\n","    <tr>\n","      <th>87714</th>\n","      <td>2020</td>\n","      <td>E05000027</td>\n","      <td>Alibon</td>\n","      <td>wd22</td>\n","      <td>0</td>\n","      <td>Total</td>\n","      <td>200</td>\n","      <td>All Ages</td>\n","      <td>n_persons</td>\n","      <td>Number of persons</td>\n","      <td>10907</td>\n","    </tr>\n","    <tr>\n","      <th>87732</th>\n","      <td>2020</td>\n","      <td>E05000028</td>\n","      <td>Becontree</td>\n","      <td>wd22</td>\n","      <td>0</td>\n","      <td>Total</td>\n","      <td>200</td>\n","      <td>All Ages</td>\n","      <td>n_persons</td>\n","      <td>Number of persons</td>\n","      <td>15182</td>\n","    </tr>\n","    <tr>\n","      <th>87750</th>\n","      <td>2020</td>\n","      <td>E05000029</td>\n","      <td>Chadwell Heath</td>\n","      <td>wd22</td>\n","      <td>0</td>\n","      <td>Total</td>\n","      <td>200</td>\n","      <td>All Ages</td>\n","      <td>n_persons</td>\n","      <td>Number of persons</td>\n","      <td>11463</td>\n","    </tr>\n","    <tr>\n","      <th>87768</th>\n","      <td>2020</td>\n","      <td>E05000030</td>\n","      <td>Eastbrook</td>\n","      <td>wd22</td>\n","      <td>0</td>\n","      <td>Total</td>\n","      <td>200</td>\n","      <td>All Ages</td>\n","      <td>n_persons</td>\n","      <td>Number of persons</td>\n","      <td>11557</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6264</th>\n","      <td>2021</td>\n","      <td>E47000007</td>\n","      <td>West Midlands</td>\n","      <td>cauth22</td>\n","      <td>0</td>\n","      <td>Total</td>\n","      <td>200</td>\n","      <td>All Ages</td>\n","      <td>n_persons</td>\n","      <td>Number of persons</td>\n","      <td>2916132</td>\n","    </tr>\n","    <tr>\n","      <th>6282</th>\n","      <td>2021</td>\n","      <td>E47000008</td>\n","      <td>Cambridgeshire and Peterborough</td>\n","      <td>cauth22</td>\n","      <td>0</td>\n","      <td>Total</td>\n","      <td>200</td>\n","      <td>All Ages</td>\n","      <td>n_persons</td>\n","      <td>Number of persons</td>\n","      <td>896756</td>\n","    </tr>\n","    <tr>\n","      <th>6300</th>\n","      <td>2021</td>\n","      <td>E47000009</td>\n","      <td>West of England</td>\n","      <td>cauth22</td>\n","      <td>0</td>\n","      <td>Total</td>\n","      <td>200</td>\n","      <td>All Ages</td>\n","      <td>n_persons</td>\n","      <td>Number of persons</td>\n","      <td>954276</td>\n","    </tr>\n","    <tr>\n","      <th>6318</th>\n","      <td>2021</td>\n","      <td>E47000010</td>\n","      <td>North East</td>\n","      <td>cauth22</td>\n","      <td>0</td>\n","      <td>Total</td>\n","      <td>200</td>\n","      <td>All Ages</td>\n","      <td>n_persons</td>\n","      <td>Number of persons</td>\n","      <td>1139626</td>\n","    </tr>\n","    <tr>\n","      <th>6336</th>\n","      <td>2021</td>\n","      <td>E47000011</td>\n","      <td>North of Tyne</td>\n","      <td>cauth22</td>\n","      <td>0</td>\n","      <td>Total</td>\n","      <td>200</td>\n","      <td>All Ages</td>\n","      <td>n_persons</td>\n","      <td>Number of persons</td>\n","      <td>828973</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7554 rows × 11 columns</p>\n","</div>"],"text/plain":["       date geography_code                   geography_name geography_type   \n","87696  2020      E05000026                            Abbey           wd22  \\\n","87714  2020      E05000027                           Alibon           wd22   \n","87732  2020      E05000028                        Becontree           wd22   \n","87750  2020      E05000029                   Chadwell Heath           wd22   \n","87768  2020      E05000030                        Eastbrook           wd22   \n","...     ...            ...                              ...            ...   \n","6264   2021      E47000007                    West Midlands        cauth22   \n","6282   2021      E47000008  Cambridgeshire and Peterborough        cauth22   \n","6300   2021      E47000009                  West of England        cauth22   \n","6318   2021      E47000010                       North East        cauth22   \n","6336   2021      E47000011                    North of Tyne        cauth22   \n","\n","       gender_code gender_name  age_code  age_name variable_code   \n","87696            0       Total       200  All Ages     n_persons  \\\n","87714            0       Total       200  All Ages     n_persons   \n","87732            0       Total       200  All Ages     n_persons   \n","87750            0       Total       200  All Ages     n_persons   \n","87768            0       Total       200  All Ages     n_persons   \n","...            ...         ...       ...       ...           ...   \n","6264             0       Total       200  All Ages     n_persons   \n","6282             0       Total       200  All Ages     n_persons   \n","6300             0       Total       200  All Ages     n_persons   \n","6318             0       Total       200  All Ages     n_persons   \n","6336             0       Total       200  All Ages     n_persons   \n","\n","           variable_name    value  \n","87696  Number of persons    16149  \n","87714  Number of persons    10907  \n","87732  Number of persons    15182  \n","87750  Number of persons    11463  \n","87768  Number of persons    11557  \n","...                  ...      ...  \n","6264   Number of persons  2916132  \n","6282   Number of persons   896756  \n","6300   Number of persons   954276  \n","6318   Number of persons  1139626  \n","6336   Number of persons   828973  \n","\n","[7554 rows x 11 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["population_data = pd.read_csv(f'{DATA_DIR}/population-estimates/population-estimates.csv')\n","population_data = population_data[population_data.age_name == \"All Ages\"]\n","group = population_data\n","#population_data = population_data[population_data.date == max(population_data['date'])]\n","population_data = population_data.loc[population_data.groupby('geography_code')['date'].idxmax()]\n","#population_data = population_data.query()\n","#print(group)\n","population_data"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>geography_code</th>\n","      <th>variable_name</th>\n","      <th>variable_unit</th>\n","      <th>value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>172260</th>\n","      <td>2020</td>\n","      <td>E05000026</td>\n","      <td>GVA</td>\n","      <td>£m</td>\n","      <td>487.120255</td>\n","    </tr>\n","    <tr>\n","      <th>172261</th>\n","      <td>2020</td>\n","      <td>E05000027</td>\n","      <td>GVA</td>\n","      <td>£m</td>\n","      <td>118.668199</td>\n","    </tr>\n","    <tr>\n","      <th>172262</th>\n","      <td>2020</td>\n","      <td>E05000028</td>\n","      <td>GVA</td>\n","      <td>£m</td>\n","      <td>80.469218</td>\n","    </tr>\n","    <tr>\n","      <th>172263</th>\n","      <td>2020</td>\n","      <td>E05000029</td>\n","      <td>GVA</td>\n","      <td>£m</td>\n","      <td>107.323509</td>\n","    </tr>\n","    <tr>\n","      <th>172264</th>\n","      <td>2020</td>\n","      <td>E05000030</td>\n","      <td>GVA</td>\n","      <td>£m</td>\n","      <td>201.595050</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>179242</th>\n","      <td>2020</td>\n","      <td>E05013859</td>\n","      <td>GVA</td>\n","      <td>£m</td>\n","      <td>108.915558</td>\n","    </tr>\n","    <tr>\n","      <th>179243</th>\n","      <td>2020</td>\n","      <td>E05013860</td>\n","      <td>GVA</td>\n","      <td>£m</td>\n","      <td>82.712088</td>\n","    </tr>\n","    <tr>\n","      <th>179244</th>\n","      <td>2020</td>\n","      <td>E05013861</td>\n","      <td>GVA</td>\n","      <td>£m</td>\n","      <td>189.998642</td>\n","    </tr>\n","    <tr>\n","      <th>179245</th>\n","      <td>2020</td>\n","      <td>E05013862</td>\n","      <td>GVA</td>\n","      <td>£m</td>\n","      <td>58.629043</td>\n","    </tr>\n","    <tr>\n","      <th>179246</th>\n","      <td>2020</td>\n","      <td>E05013863</td>\n","      <td>GVA</td>\n","      <td>£m</td>\n","      <td>23.733712</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6987 rows × 5 columns</p>\n","</div>"],"text/plain":["        date geography_code variable_name variable_unit       value\n","172260  2020      E05000026           GVA            £m  487.120255\n","172261  2020      E05000027           GVA            £m  118.668199\n","172262  2020      E05000028           GVA            £m   80.469218\n","172263  2020      E05000029           GVA            £m  107.323509\n","172264  2020      E05000030           GVA            £m  201.595050\n","...      ...            ...           ...           ...         ...\n","179242  2020      E05013859           GVA            £m  108.915558\n","179243  2020      E05013860           GVA            £m   82.712088\n","179244  2020      E05013861           GVA            £m  189.998642\n","179245  2020      E05013862           GVA            £m   58.629043\n","179246  2020      E05013863           GVA            £m   23.733712\n","\n","[6987 rows x 5 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["gva = pd.read_csv(f'{DATA_DIR}/gva/gva.csv')\n","#gva['date'].astype(float)\n","#gva[gva['geography_code'].str.startswith('E09')]\n","gva['date'] = pd.to_datetime(gva['date'])\n","gva['date'] = gva['date'].dt.year\n","gva = gva.loc[gva.groupby('geography_code')['date'].idxmax()]\n","gva[gva['geography_code'].str.startswith('E05')]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>geography_code</th>\n","      <th>variable_name</th>\n","      <th>value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>E05000650</td>\n","      <td>Area in sq km</td>\n","      <td>6.556496</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>E05000651</td>\n","      <td>Area in sq km</td>\n","      <td>8.998946</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>E05000652</td>\n","      <td>Area in sq km</td>\n","      <td>3.719582</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>E05000653</td>\n","      <td>Area in sq km</td>\n","      <td>7.340085</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>E05000654</td>\n","      <td>Area in sq km</td>\n","      <td>3.497711</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1646</th>\n","      <td>E11000007</td>\n","      <td>Area in sq km</td>\n","      <td>538.992682</td>\n","    </tr>\n","    <tr>\n","      <th>1647</th>\n","      <td>E12000001</td>\n","      <td>Area in sq km</td>\n","      <td>8563.803423</td>\n","    </tr>\n","    <tr>\n","      <th>1648</th>\n","      <td>E12000002</td>\n","      <td>Area in sq km</td>\n","      <td>14103.955722</td>\n","    </tr>\n","    <tr>\n","      <th>1649</th>\n","      <td>E12000003</td>\n","      <td>Area in sq km</td>\n","      <td>15369.599209</td>\n","    </tr>\n","    <tr>\n","      <th>1650</th>\n","      <td>E12999901</td>\n","      <td>Area in sq km</td>\n","      <td>38037.358354</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1650 rows × 3 columns</p>\n","</div>"],"text/plain":["     geography_code  variable_name         value\n","0         E05000650  Area in sq km      6.556496\n","1         E05000651  Area in sq km      8.998946\n","2         E05000652  Area in sq km      3.719582\n","3         E05000653  Area in sq km      7.340085\n","4         E05000654  Area in sq km      3.497711\n","...             ...            ...           ...\n","1646      E11000007  Area in sq km    538.992682\n","1647      E12000001  Area in sq km   8563.803423\n","1648      E12000002  Area in sq km  14103.955722\n","1649      E12000003  Area in sq km  15369.599209\n","1650      E12999901  Area in sq km  38037.358354\n","\n","[1650 rows x 3 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["area_of_place = pd.read_csv(f'{DATA_DIR}/geo/area_of_places.csv')\n","#@TODO temporary filter to remove\n","area_of_place.drop_duplicates(subset=['geography_code'], inplace=True)\n","# len(area_of_place.geography_code)\n","# l1 = area_of_place.geography_code.to_list()\n","# l2 = area_of_place.geography_code.unique()\n","# seen = set()\n","# dupes = [x for x in l1 if x in seen or seen.add(x)]\n","# print(dupes)\n","area_of_place"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>geography_code</th>\n","      <th>variable_name</th>\n","      <th>value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2022</td>\n","      <td>E05000026</td>\n","      <td>Number of households</td>\n","      <td>5800</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2022</td>\n","      <td>E05000027</td>\n","      <td>Number of households</td>\n","      <td>4090</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2022</td>\n","      <td>E05000028</td>\n","      <td>Number of households</td>\n","      <td>5380</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2022</td>\n","      <td>E05000029</td>\n","      <td>Number of households</td>\n","      <td>4300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2022</td>\n","      <td>E05000030</td>\n","      <td>Number of households</td>\n","      <td>4100</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7825</th>\n","      <td>2022</td>\n","      <td>W05001034</td>\n","      <td>Number of households</td>\n","      <td>940</td>\n","    </tr>\n","    <tr>\n","      <th>7826</th>\n","      <td>2022</td>\n","      <td>W05001035</td>\n","      <td>Number of households</td>\n","      <td>2310</td>\n","    </tr>\n","    <tr>\n","      <th>7827</th>\n","      <td>2022</td>\n","      <td>W05001036</td>\n","      <td>Number of households</td>\n","      <td>1910</td>\n","    </tr>\n","    <tr>\n","      <th>7828</th>\n","      <td>2022</td>\n","      <td>W05001037</td>\n","      <td>Number of households</td>\n","      <td>860</td>\n","    </tr>\n","    <tr>\n","      <th>7829</th>\n","      <td>2022</td>\n","      <td>W05001038</td>\n","      <td>Number of households</td>\n","      <td>1130</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7921 rows × 4 columns</p>\n","</div>"],"text/plain":["      date geography_code         variable_name  value\n","0     2022      E05000026  Number of households   5800\n","1     2022      E05000027  Number of households   4090\n","2     2022      E05000028  Number of households   5380\n","3     2022      E05000029  Number of households   4300\n","4     2022      E05000030  Number of households   4100\n","...    ...            ...                   ...    ...\n","7825  2022      W05001034  Number of households    940\n","7826  2022      W05001035  Number of households   2310\n","7827  2022      W05001036  Number of households   1910\n","7828  2022      W05001037  Number of households    860\n","7829  2022      W05001038  Number of households   1130\n","\n","[7921 rows x 4 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["households = pd.read_csv(f'{DATA_DIR}/households/households.csv')\n","households = households.loc[households.groupby('geography_code')['date'].idxmax()]\n","households"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>geography_code.ba</th>\n","      <th>geography_code</th>\n","      <th>geography_name</th>\n","      <th>geography_type</th>\n","      <th>variable_code</th>\n","      <th>variable_name</th>\n","      <th>value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>14876</th>\n","      <td>2022</td>\n","      <td>E0701</td>\n","      <td>E06000001</td>\n","      <td>Hartlepool</td>\n","      <td>UA</td>\n","      <td>council_tax_working_age</td>\n","      <td>council_tax_working_age</td>\n","      <td>8712.0</td>\n","    </tr>\n","    <tr>\n","      <th>16302</th>\n","      <td>2022</td>\n","      <td>E0702</td>\n","      <td>E06000002</td>\n","      <td>Middlesbrough</td>\n","      <td>UA</td>\n","      <td>council_tax_working_age</td>\n","      <td>council_tax_working_age</td>\n","      <td>12738.0</td>\n","    </tr>\n","    <tr>\n","      <th>17480</th>\n","      <td>2022</td>\n","      <td>E0703</td>\n","      <td>E06000003</td>\n","      <td>Redcar &amp; Cleveland</td>\n","      <td>UA</td>\n","      <td>council_tax_working_age</td>\n","      <td>council_tax_working_age</td>\n","      <td>8028.0</td>\n","    </tr>\n","    <tr>\n","      <th>19185</th>\n","      <td>2022</td>\n","      <td>E0704</td>\n","      <td>E06000004</td>\n","      <td>Stockton-on-Tees</td>\n","      <td>UA</td>\n","      <td>council_tax_working_age</td>\n","      <td>council_tax_working_age</td>\n","      <td>11143.0</td>\n","    </tr>\n","    <tr>\n","      <th>13202</th>\n","      <td>2022</td>\n","      <td>E1301</td>\n","      <td>E06000005</td>\n","      <td>Darlington</td>\n","      <td>UA</td>\n","      <td>council_tax_working_age</td>\n","      <td>council_tax_working_age</td>\n","      <td>6044.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10691</th>\n","      <td>2022</td>\n","      <td>NaN</td>\n","      <td>E12000006</td>\n","      <td>East of England</td>\n","      <td>NaN</td>\n","      <td>council_tax_working_age</td>\n","      <td>council_tax_working_age</td>\n","      <td>211975.0</td>\n","    </tr>\n","    <tr>\n","      <th>10722</th>\n","      <td>2022</td>\n","      <td>NaN</td>\n","      <td>E12000007</td>\n","      <td>London</td>\n","      <td>NaN</td>\n","      <td>council_tax_working_age</td>\n","      <td>council_tax_working_age</td>\n","      <td>445550.0</td>\n","    </tr>\n","    <tr>\n","      <th>10815</th>\n","      <td>2022</td>\n","      <td>NaN</td>\n","      <td>E12000008</td>\n","      <td>South East England</td>\n","      <td>NaN</td>\n","      <td>council_tax_working_age</td>\n","      <td>council_tax_working_age</td>\n","      <td>284443.0</td>\n","    </tr>\n","    <tr>\n","      <th>10846</th>\n","      <td>2022</td>\n","      <td>NaN</td>\n","      <td>E12000009</td>\n","      <td>South West England</td>\n","      <td>NaN</td>\n","      <td>council_tax_working_age</td>\n","      <td>council_tax_working_age</td>\n","      <td>207054.0</td>\n","    </tr>\n","    <tr>\n","      <th>10660</th>\n","      <td>2022</td>\n","      <td>NaN</td>\n","      <td>E92000001</td>\n","      <td>England</td>\n","      <td>NaN</td>\n","      <td>council_tax_working_age</td>\n","      <td>council_tax_working_age</td>\n","      <td>2448767.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>343 rows × 8 columns</p>\n","</div>"],"text/plain":["       date geography_code.ba geography_code      geography_name   \n","14876  2022             E0701      E06000001          Hartlepool  \\\n","16302  2022             E0702      E06000002       Middlesbrough   \n","17480  2022             E0703      E06000003  Redcar & Cleveland   \n","19185  2022             E0704      E06000004    Stockton-on-Tees   \n","13202  2022             E1301      E06000005          Darlington   \n","...     ...               ...            ...                 ...   \n","10691  2022               NaN      E12000006     East of England   \n","10722  2022               NaN      E12000007              London   \n","10815  2022               NaN      E12000008  South East England   \n","10846  2022               NaN      E12000009  South West England   \n","10660  2022               NaN      E92000001             England   \n","\n","      geography_type            variable_code            variable_name   \n","14876             UA  council_tax_working_age  council_tax_working_age  \\\n","16302             UA  council_tax_working_age  council_tax_working_age   \n","17480             UA  council_tax_working_age  council_tax_working_age   \n","19185             UA  council_tax_working_age  council_tax_working_age   \n","13202             UA  council_tax_working_age  council_tax_working_age   \n","...              ...                      ...                      ...   \n","10691            NaN  council_tax_working_age  council_tax_working_age   \n","10722            NaN  council_tax_working_age  council_tax_working_age   \n","10815            NaN  council_tax_working_age  council_tax_working_age   \n","10846            NaN  council_tax_working_age  council_tax_working_age   \n","10660            NaN  council_tax_working_age  council_tax_working_age   \n","\n","           value  \n","14876     8712.0  \n","16302    12738.0  \n","17480     8028.0  \n","19185    11143.0  \n","13202     6044.0  \n","...          ...  \n","10691   211975.0  \n","10722   445550.0  \n","10815   284443.0  \n","10846   207054.0  \n","10660  2448767.0  \n","\n","[343 rows x 8 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["council_tax_data = pd.read_csv(f'{DATA_DIR}/council-tax-support/council-tax-support.csv')\n","#council_tax_data = council_tax_data[council_tax_data.date == max(council_tax_data.date)]\n","council_tax_data['date'] = pd.to_datetime(council_tax_data['date'])\n","council_tax_data['date'] = council_tax_data['date'].dt.year\n","council_tax_data = council_tax_data.loc[council_tax_data.groupby(['geography_code', 'variable_name'])['date'].idxmax()]\n","council_tax_data.replace(\"pensioners\", \"council_tax_pensioners\", inplace=True)\n","council_tax_data.replace(\"working_age\", \"council_tax_working_age\", inplace=True)\n","council_tax_data[council_tax_data.variable_name == \"council_tax_working_age\"]\n","#council_tax_data[council_tax_data.geography_code.str.startswith('E05')]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Year</th>\n","      <th>Age of Child (years and bands)</th>\n","      <th>Gender of Child</th>\n","      <th>Family Type</th>\n","      <th>Work Status</th>\n","      <th>variable_name</th>\n","      <th>geography_code</th>\n","      <th>value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11474</th>\n","      <td>2021/22</td>\n","      <td>Total</td>\n","      <td>Total</td>\n","      <td>Total</td>\n","      <td>Total</td>\n","      <td>children_in_low_income</td>\n","      <td>E08000035</td>\n","      <td>39995.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          Year Age of Child (years and bands) Gender of Child Family Type   \n","11474  2021/22                          Total           Total       Total  \\\n","\n","      Work Status           variable_name geography_code    value  \n","11474       Total  children_in_low_income      E08000035  39995.0  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["clif_data = pd.read_csv(f'{DATA_DIR}/clif/clif_REL.csv')\n","clif_data = clif_data[\n","    (clif_data['Age of Child (years and bands)'] == 'Total') &\n","    (clif_data['Gender of Child'] == 'Total') &\n","    (clif_data['Family Type'] == 'Total') &\n","    (clif_data['Work Status'] == 'Total') &\n","    (clif_data.Year == max(clif_data.Year))\n","]\n","clif_data[clif_data.geography_code == 'E08000035']"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>geography_code</th>\n","      <th>date</th>\n","      <th>value</th>\n","      <th>variable_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>E05000650</td>\n","      <td>8080</td>\n","      <td>3390</td>\n","      <td>number_of_children</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>E05000651</td>\n","      <td>8080</td>\n","      <td>2530</td>\n","      <td>number_of_children</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>E05000652</td>\n","      <td>8080</td>\n","      <td>3722</td>\n","      <td>number_of_children</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>E05000653</td>\n","      <td>8080</td>\n","      <td>2813</td>\n","      <td>number_of_children</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>E05000654</td>\n","      <td>8080</td>\n","      <td>4875</td>\n","      <td>number_of_children</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1315</th>\n","      <td>E47000003</td>\n","      <td>8084</td>\n","      <td>586078</td>\n","      <td>number_of_children</td>\n","    </tr>\n","    <tr>\n","      <th>1316</th>\n","      <td>E47000004</td>\n","      <td>8084</td>\n","      <td>346827</td>\n","      <td>number_of_children</td>\n","    </tr>\n","    <tr>\n","      <th>1317</th>\n","      <td>E47000006</td>\n","      <td>8084</td>\n","      <td>159599</td>\n","      <td>number_of_children</td>\n","    </tr>\n","    <tr>\n","      <th>1318</th>\n","      <td>E47000010</td>\n","      <td>8084</td>\n","      <td>247569</td>\n","      <td>number_of_children</td>\n","    </tr>\n","    <tr>\n","      <th>1319</th>\n","      <td>E47000011</td>\n","      <td>8084</td>\n","      <td>179841</td>\n","      <td>number_of_children</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1320 rows × 4 columns</p>\n","</div>"],"text/plain":["     geography_code  date   value       variable_name\n","0         E05000650  8080    3390  number_of_children\n","1         E05000651  8080    2530  number_of_children\n","2         E05000652  8080    3722  number_of_children\n","3         E05000653  8080    2813  number_of_children\n","4         E05000654  8080    4875  number_of_children\n","...             ...   ...     ...                 ...\n","1315      E47000003  8084  586078  number_of_children\n","1316      E47000004  8084  346827  number_of_children\n","1317      E47000006  8084  159599  number_of_children\n","1318      E47000010  8084  247569  number_of_children\n","1319      E47000011  8084  179841  number_of_children\n","\n","[1320 rows x 4 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["number_of_persons = pd.read_csv(f'{DATA_DIR}/population-estimates/population-estimates-ages.csv')\n","number_of_children = number_of_persons[number_of_persons.age_band.isin(['0-4', '5-10', '11-15', '16-19'])]\n","number_of_children = number_of_children.groupby('geography_code').sum(numeric_only=True).reset_index()\n","number_of_children['variable_name'] = 'number_of_children'\n","number_of_children"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>geography_code</th>\n","      <th>value</th>\n","      <th>variable_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>E12000001</td>\n","      <td>500000.0</td>\n","      <td>Households in poverty</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>E12000002</td>\n","      <td>1300000.0</td>\n","      <td>Households in poverty</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>E12000003</td>\n","      <td>1100000.0</td>\n","      <td>Households in poverty</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  geography_code      value          variable_name\n","0      E12000001   500000.0  Households in poverty\n","1      E12000002  1300000.0  Households in poverty\n","2      E12000003  1100000.0  Households in poverty"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["#number of households in poverty\n","households_in_poverty = pd.read_csv(f'{DATA_DIR}/hbai/Type of Individual by Age Category.csv')\n","households_in_poverty = households_in_poverty[households_in_poverty.variable_name == \"In low income (below threshold)\"]\n","\n","def three_year_average(data):\n","    #@TODO function will need work to account for 3 year average of any period given.\n","    #filtering out 2020-21 as no data was collected\n","    data = data[data[\"Financial Year\"] != \"2020-21\"]\n","    #getting a list of dates\n","    dates = data[\"Financial Year\"].unique()\n","    most_recent_dates = list(dates[-2:])\n","    #print(most_recent)\n","    data = data[data[\"Financial Year\"].isin(most_recent_dates)]\n","    #calculating a 2 year average according to user guidance\n","    data = data.groupby('geography_code').sum(numeric_only=True) / len(most_recent_dates)\n","    #rounding to nearest 0.1mil, according to user guidance.\n","    data = data.round(-5).reset_index()\n","    return data\n","\n","households_in_poverty = three_year_average(households_in_poverty)\n","\n","households_in_poverty['variable_name'] = 'Households in poverty'\n","households_in_poverty"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>geography_code</th>\n","      <th>value</th>\n","      <th>variable_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>E12000001</td>\n","      <td>100000.0</td>\n","      <td>households_low_income_no_savings</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>E12000002</td>\n","      <td>400000.0</td>\n","      <td>households_low_income_no_savings</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>E12000003</td>\n","      <td>300000.0</td>\n","      <td>households_low_income_no_savings</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  geography_code     value                     variable_name\n","0      E12000001  100000.0  households_low_income_no_savings\n","1      E12000002  400000.0  households_low_income_no_savings\n","2      E12000003  300000.0  households_low_income_no_savings"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["savings = pd.read_csv(f'{DATA_DIR}/hbai/Savings and Investments of Adults in the Family of the Individual.csv')\n","savings = savings[savings['Financial Year'] == max(savings['Financial Year'])]\n","savings = savings[savings.variable_name == 'In low income (below threshold)']\n","savings = savings[savings['Savings and Investments of Adults in the Family of the Individual'] == 'No savings']\n","savings = three_year_average(savings)\n","savings['variable_name'] = 'households_low_income_no_savings'\n","savings\n","#save each geog_code into 'src/place/EXXXXXX/_data/' and then can build the visualisations in place.njk on a conidtional statement if that data exists."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":[" # Index of Multiple deprivation\n","data = pd.read_csv(f'{DATA_DIR}/imd/imd.csv')\n","data  = data[data.variable_name == 'Average score'] #adding this as in future there will be measures for each age cat.#\n","imd = data.loc[data.dataset == 'IMD'].copy()\n","imd['variable_name'] = 'imd_average_score'\n","\n","imd_older_people = data.loc[data.dataset == 'IDAOPI'].copy()\n","imd_older_people['variable_name'] = 'imd_older_people'\n","\n","imd_children = data.loc[data.dataset == \"IDACI\"].copy()\n","imd_children['variable_name'] = 'imd_children'\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>geography_code</th>\n","      <th>geography_name</th>\n","      <th>variable_code</th>\n","      <th>variable_name</th>\n","      <th>value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>16850</th>\n","      <td>2022-12-01</td>\n","      <td>E06000005</td>\n","      <td>Darlington</td>\n","      <td>111</td>\n","      <td>economic_inactivity_16_64</td>\n","      <td>20.9</td>\n","    </tr>\n","    <tr>\n","      <th>16853</th>\n","      <td>2022-12-01</td>\n","      <td>E06000047</td>\n","      <td>County Durham</td>\n","      <td>111</td>\n","      <td>economic_inactivity_16_64</td>\n","      <td>24.3</td>\n","    </tr>\n","    <tr>\n","      <th>16856</th>\n","      <td>2022-12-01</td>\n","      <td>E06000001</td>\n","      <td>Hartlepool</td>\n","      <td>111</td>\n","      <td>economic_inactivity_16_64</td>\n","      <td>27.3</td>\n","    </tr>\n","    <tr>\n","      <th>16859</th>\n","      <td>2022-12-01</td>\n","      <td>E06000002</td>\n","      <td>Middlesbrough</td>\n","      <td>111</td>\n","      <td>economic_inactivity_16_64</td>\n","      <td>29.3</td>\n","    </tr>\n","    <tr>\n","      <th>16862</th>\n","      <td>2022-12-01</td>\n","      <td>E06000057</td>\n","      <td>Northumberland</td>\n","      <td>111</td>\n","      <td>economic_inactivity_16_64</td>\n","      <td>25.8</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17069</th>\n","      <td>2022-12-01</td>\n","      <td>E10000017</td>\n","      <td>Lancashire</td>\n","      <td>111</td>\n","      <td>economic_inactivity_16_64</td>\n","      <td>23.5</td>\n","    </tr>\n","    <tr>\n","      <th>17072</th>\n","      <td>2022-12-01</td>\n","      <td>E10000023</td>\n","      <td>North Yorkshire</td>\n","      <td>111</td>\n","      <td>economic_inactivity_16_64</td>\n","      <td>20.0</td>\n","    </tr>\n","    <tr>\n","      <th>17075</th>\n","      <td>2022-12-01</td>\n","      <td>E12000001</td>\n","      <td>North East</td>\n","      <td>111</td>\n","      <td>economic_inactivity_16_64</td>\n","      <td>26.0</td>\n","    </tr>\n","    <tr>\n","      <th>17078</th>\n","      <td>2022-12-01</td>\n","      <td>E12000002</td>\n","      <td>North West</td>\n","      <td>111</td>\n","      <td>economic_inactivity_16_64</td>\n","      <td>23.3</td>\n","    </tr>\n","    <tr>\n","      <th>17081</th>\n","      <td>2022-12-01</td>\n","      <td>E12000003</td>\n","      <td>Yorkshire and The Humber</td>\n","      <td>111</td>\n","      <td>economic_inactivity_16_64</td>\n","      <td>22.6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>78 rows × 6 columns</p>\n","</div>"],"text/plain":["             date geography_code            geography_name  variable_code   \n","16850  2022-12-01      E06000005                Darlington            111  \\\n","16853  2022-12-01      E06000047             County Durham            111   \n","16856  2022-12-01      E06000001                Hartlepool            111   \n","16859  2022-12-01      E06000002             Middlesbrough            111   \n","16862  2022-12-01      E06000057            Northumberland            111   \n","...           ...            ...                       ...            ...   \n","17069  2022-12-01      E10000017                Lancashire            111   \n","17072  2022-12-01      E10000023           North Yorkshire            111   \n","17075  2022-12-01      E12000001                North East            111   \n","17078  2022-12-01      E12000002                North West            111   \n","17081  2022-12-01      E12000003  Yorkshire and The Humber            111   \n","\n","                   variable_name  value  \n","16850  economic_inactivity_16_64   20.9  \n","16853  economic_inactivity_16_64   24.3  \n","16856  economic_inactivity_16_64   27.3  \n","16859  economic_inactivity_16_64   29.3  \n","16862  economic_inactivity_16_64   25.8  \n","...                          ...    ...  \n","17069  economic_inactivity_16_64   23.5  \n","17072  economic_inactivity_16_64   20.0  \n","17075  economic_inactivity_16_64   26.0  \n","17078  economic_inactivity_16_64   23.3  \n","17081  economic_inactivity_16_64   22.6  \n","\n","[78 rows x 6 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["labour_market = pd.read_csv(f'{DATA_DIR}/labour-market/labour-market.csv')\n","unemployment = labour_market[labour_market.variable_name == \"Unemployment rate - aged 16-64\"]\n","unemployment = unemployment[unemployment.date == max(unemployment.date)]\n","unemployment['variable_name'] = 'unemployment_rate_16_64'\n","\n","labour_market = pd.read_csv(f'{DATA_DIR}/labour-market/labour-market.csv')\n","economic_inactivity = labour_market[labour_market.variable_name == \"% who are economically inactive - aged 16-64\"]\n","economic_inactivity = economic_inactivity[economic_inactivity.date == max(economic_inactivity.date)]\n","economic_inactivity = economic_inactivity.replace(\"% who are economically inactive - aged 16-64\",\"economic_inactivity_16_64\")\n","\n","economic_inactivity"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dt_idx</th>\n","      <th>Month</th>\n","      <th>geography_code</th>\n","      <th>value</th>\n","      <th>variable_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1651</th>\n","      <td>4896</td>\n","      <td>2023-02-01</td>\n","      <td>E08000001</td>\n","      <td>12115.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>1710</th>\n","      <td>5073</td>\n","      <td>2023-02-01</td>\n","      <td>E08000002</td>\n","      <td>6472.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>1769</th>\n","      <td>5250</td>\n","      <td>2023-02-01</td>\n","      <td>E08000003</td>\n","      <td>30631.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>1828</th>\n","      <td>5427</td>\n","      <td>2023-02-01</td>\n","      <td>E08000004</td>\n","      <td>8589.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>1887</th>\n","      <td>5604</td>\n","      <td>2023-02-01</td>\n","      <td>E08000005</td>\n","      <td>10194.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>1946</th>\n","      <td>5781</td>\n","      <td>2023-02-01</td>\n","      <td>E08000006</td>\n","      <td>14051.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>2005</th>\n","      <td>5958</td>\n","      <td>2023-02-01</td>\n","      <td>E08000007</td>\n","      <td>8977.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>2064</th>\n","      <td>6135</td>\n","      <td>2023-02-01</td>\n","      <td>E08000008</td>\n","      <td>10009.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>2123</th>\n","      <td>6312</td>\n","      <td>2023-02-01</td>\n","      <td>E08000009</td>\n","      <td>6830.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>2182</th>\n","      <td>6489</td>\n","      <td>2023-02-01</td>\n","      <td>E08000010</td>\n","      <td>11410.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>2949</th>\n","      <td>8790</td>\n","      <td>2023-02-01</td>\n","      <td>E08000011</td>\n","      <td>8894.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>3008</th>\n","      <td>8967</td>\n","      <td>2023-02-01</td>\n","      <td>E08000012</td>\n","      <td>32963.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>3126</th>\n","      <td>9321</td>\n","      <td>2023-02-01</td>\n","      <td>E08000013</td>\n","      <td>7986.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>3067</th>\n","      <td>9144</td>\n","      <td>2023-02-01</td>\n","      <td>E08000014</td>\n","      <td>11859.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>3185</th>\n","      <td>9498</td>\n","      <td>2023-02-01</td>\n","      <td>E08000015</td>\n","      <td>15120.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>3952</th>\n","      <td>11799</td>\n","      <td>2023-02-01</td>\n","      <td>E08000016</td>\n","      <td>9759.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>4011</th>\n","      <td>11976</td>\n","      <td>2023-02-01</td>\n","      <td>E08000017</td>\n","      <td>11750.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>4070</th>\n","      <td>12153</td>\n","      <td>2023-02-01</td>\n","      <td>E08000018</td>\n","      <td>11244.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>4129</th>\n","      <td>12330</td>\n","      <td>2023-02-01</td>\n","      <td>E08000019</td>\n","      <td>25915.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>707</th>\n","      <td>2064</td>\n","      <td>2023-02-01</td>\n","      <td>E08000021</td>\n","      <td>14164.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>766</th>\n","      <td>2241</td>\n","      <td>2023-02-01</td>\n","      <td>E08000022</td>\n","      <td>8873.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>825</th>\n","      <td>2418</td>\n","      <td>2023-02-01</td>\n","      <td>E08000023</td>\n","      <td>9116.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>884</th>\n","      <td>2595</td>\n","      <td>2023-02-01</td>\n","      <td>E08000024</td>\n","      <td>15589.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>4188</th>\n","      <td>12507</td>\n","      <td>2023-02-01</td>\n","      <td>E08000032</td>\n","      <td>19024.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>4247</th>\n","      <td>12684</td>\n","      <td>2023-02-01</td>\n","      <td>E08000033</td>\n","      <td>7081.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>4306</th>\n","      <td>12861</td>\n","      <td>2023-02-01</td>\n","      <td>E08000034</td>\n","      <td>13901.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>4365</th>\n","      <td>13038</td>\n","      <td>2023-02-01</td>\n","      <td>E08000035</td>\n","      <td>31758.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>4424</th>\n","      <td>13215</td>\n","      <td>2023-02-01</td>\n","      <td>E08000036</td>\n","      <td>15421.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","    <tr>\n","      <th>648</th>\n","      <td>1887</td>\n","      <td>2023-02-01</td>\n","      <td>E08000037</td>\n","      <td>10042.0</td>\n","      <td>HB_claimants</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      dt_idx      Month geography_code    value variable_name\n","1651    4896 2023-02-01      E08000001  12115.0  HB_claimants\n","1710    5073 2023-02-01      E08000002   6472.0  HB_claimants\n","1769    5250 2023-02-01      E08000003  30631.0  HB_claimants\n","1828    5427 2023-02-01      E08000004   8589.0  HB_claimants\n","1887    5604 2023-02-01      E08000005  10194.0  HB_claimants\n","1946    5781 2023-02-01      E08000006  14051.0  HB_claimants\n","2005    5958 2023-02-01      E08000007   8977.0  HB_claimants\n","2064    6135 2023-02-01      E08000008  10009.0  HB_claimants\n","2123    6312 2023-02-01      E08000009   6830.0  HB_claimants\n","2182    6489 2023-02-01      E08000010  11410.0  HB_claimants\n","2949    8790 2023-02-01      E08000011   8894.0  HB_claimants\n","3008    8967 2023-02-01      E08000012  32963.0  HB_claimants\n","3126    9321 2023-02-01      E08000013   7986.0  HB_claimants\n","3067    9144 2023-02-01      E08000014  11859.0  HB_claimants\n","3185    9498 2023-02-01      E08000015  15120.0  HB_claimants\n","3952   11799 2023-02-01      E08000016   9759.0  HB_claimants\n","4011   11976 2023-02-01      E08000017  11750.0  HB_claimants\n","4070   12153 2023-02-01      E08000018  11244.0  HB_claimants\n","4129   12330 2023-02-01      E08000019  25915.0  HB_claimants\n","707     2064 2023-02-01      E08000021  14164.0  HB_claimants\n","766     2241 2023-02-01      E08000022   8873.0  HB_claimants\n","825     2418 2023-02-01      E08000023   9116.0  HB_claimants\n","884     2595 2023-02-01      E08000024  15589.0  HB_claimants\n","4188   12507 2023-02-01      E08000032  19024.0  HB_claimants\n","4247   12684 2023-02-01      E08000033   7081.0  HB_claimants\n","4306   12861 2023-02-01      E08000034  13901.0  HB_claimants\n","4365   13038 2023-02-01      E08000035  31758.0  HB_claimants\n","4424   13215 2023-02-01      E08000036  15421.0  HB_claimants\n","648     1887 2023-02-01      E08000037  10042.0  HB_claimants"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["housing_benefit = pd.read_csv(f'{DATA_DIR}/HB/claimants.csv')\n","housing_benefit['Month'] = pd.to_datetime(housing_benefit['Month'])\n","housing_benefit.rename(columns={'Unnamed: 0': 'dt_idx'}, inplace=True)\n","housing_benefit = housing_benefit.loc[housing_benefit.groupby('geography_code')['dt_idx'].idxmax()]\n","housing_benefit[housing_benefit.geography_code.str.startswith('E08')]"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dt_idx</th>\n","      <th>Quarter</th>\n","      <th>geography_code</th>\n","      <th>value</th>\n","      <th>variable_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>2023-02-01</td>\n","      <td>E12000001</td>\n","      <td>537.0</td>\n","      <td>smi_loans_in_payment_households</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>29</td>\n","      <td>2023-02-01</td>\n","      <td>E12000002</td>\n","      <td>1752.0</td>\n","      <td>smi_loans_in_payment_households</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>49</td>\n","      <td>2023-02-01</td>\n","      <td>E12000003</td>\n","      <td>963.0</td>\n","      <td>smi_loans_in_payment_households</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    dt_idx    Quarter geography_code   value                    variable_name\n","9        9 2023-02-01      E12000001   537.0  smi_loans_in_payment_households\n","29      29 2023-02-01      E12000002  1752.0  smi_loans_in_payment_households\n","49      49 2023-02-01      E12000003   963.0  smi_loans_in_payment_households"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["smi = pd.read_csv(f'{DATA_DIR}/smi/smi_loans_in_payment_households.csv')\n","smi['Quarter'] = pd.to_datetime(smi['Quarter'])\n","smi.rename(columns={'Unnamed: 0': 'dt_idx'}, inplace=True)\n","smi = smi.loc[smi.groupby('geography_code')['Quarter'].idxmax()]\n","smi"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>geography_code</th>\n","      <th>geography_name</th>\n","      <th>variable_name</th>\n","      <th>value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>129</th>\n","      <td>2023</td>\n","      <td>E06000001</td>\n","      <td>Hartlepool</td>\n","      <td>Total households assessed as owed a duty</td>\n","      <td>174.0</td>\n","    </tr>\n","    <tr>\n","      <th>174</th>\n","      <td>2023</td>\n","      <td>E06000002</td>\n","      <td>Middlesbrough</td>\n","      <td>Total households assessed as owed a duty</td>\n","      <td>382.0</td>\n","    </tr>\n","    <tr>\n","      <th>208</th>\n","      <td>2023</td>\n","      <td>E06000003</td>\n","      <td>Redcar &amp; Cleveland</td>\n","      <td>Total households assessed as owed a duty</td>\n","      <td>103.0</td>\n","    </tr>\n","    <tr>\n","      <th>260</th>\n","      <td>2023</td>\n","      <td>E06000004</td>\n","      <td>Stockton-on-Tees</td>\n","      <td>Total households assessed as owed a duty</td>\n","      <td>838.0</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>2023</td>\n","      <td>E06000005</td>\n","      <td>Darlington</td>\n","      <td>Total households assessed as owed a duty</td>\n","      <td>321.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2023</td>\n","      <td>E12000006</td>\n","      <td>East of England</td>\n","      <td>Total households assessed as owed a duty</td>\n","      <td>7640.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2023</td>\n","      <td>E12000007</td>\n","      <td>London</td>\n","      <td>Total households assessed as owed a duty</td>\n","      <td>14320.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2023</td>\n","      <td>E12000008</td>\n","      <td>South East</td>\n","      <td>Total households assessed as owed a duty</td>\n","      <td>10930.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2023</td>\n","      <td>E12000009</td>\n","      <td>South West</td>\n","      <td>Total households assessed as owed a duty</td>\n","      <td>7520.0</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>2023</td>\n","      <td>E92000001</td>\n","      <td>ENGLAND</td>\n","      <td>Total households assessed as owed a duty</td>\n","      <td>79840.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>319 rows × 5 columns</p>\n","</div>"],"text/plain":["     date geography_code      geography_name   \n","129  2023      E06000001          Hartlepool  \\\n","174  2023      E06000002       Middlesbrough   \n","208  2023      E06000003  Redcar & Cleveland   \n","260  2023      E06000004    Stockton-on-Tees   \n","79   2023      E06000005          Darlington   \n","..    ...            ...                 ...   \n","7    2023      E12000006     East of England   \n","1    2023      E12000007              London   \n","9    2023      E12000008          South East   \n","10   2023      E12000009          South West   \n","0    2023      E92000001             ENGLAND   \n","\n","                                variable_name    value  \n","129  Total households assessed as owed a duty    174.0  \n","174  Total households assessed as owed a duty    382.0  \n","208  Total households assessed as owed a duty    103.0  \n","260  Total households assessed as owed a duty    838.0  \n","79   Total households assessed as owed a duty    321.0  \n","..                                        ...      ...  \n","7    Total households assessed as owed a duty   7640.0  \n","1    Total households assessed as owed a duty  14320.0  \n","9    Total households assessed as owed a duty  10930.0  \n","10   Total households assessed as owed a duty   7520.0  \n","0    Total households assessed as owed a duty  79840.0  \n","\n","[319 rows x 5 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["homelessness = pd.read_csv(f'{DATA_DIR}/statutory-homelessness/statutory-homelessness.csv')\n","homelessness['date'] = homelessness['date'].str[:4]\n","homelessness['date'] = pd.to_numeric(homelessness['date'])\n","homelessness = homelessness.loc[homelessness.groupby('geography_code')['date'].idxmax()]\n","homelessness"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["rental_prices = pd.read_csv(f'{DATA_DIR}/rental-prices/rental-prices.csv')\n","rental_prices['date'] = rental_prices['date'].str[:4]\n","rental_prices['date'] = pd.to_numeric(rental_prices['date'])\n","rental_prices = rental_prices[rental_prices.variable_code == 'Mean']\n","rental_prices = rental_prices.loc[rental_prices.groupby(['geography_code', 'property_name'])['date'].idxmax()]\n","#print(rental_prices.variable_code.unique())\n","rental_prices_pivot = rental_prices.pivot(index='property_code', columns='geography_code', values='value')\n","rental_prices_pivot.to_csv(os.path.join(SRC_DATA_DIR, 'bar_charts/current_rental_prices.csv'))"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1314\n"]}],"source":["house_prices = pd.read_csv(f'{DATA_DIR}/house-prices/house-prices.csv')\n","house_prices['date'] = pd.to_datetime(house_prices['date'])\n","house_prices = house_prices.loc[house_prices.groupby(['geography_code'])['date'].idxmax()]\n","print(len(house_prices.geography_code.unique()))\n","geo = pd.read_csv(f\"{DATA_DIR}/geo/geography_lookup.csv\")\n","\n","tot = len(geo.LAD22CD.unique()) + len(geo.WD22CD.unique())\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Concatenate the loaded data, then pivot into a table with a line per geography code. Filter this to only include geographies that are in the canonical list of areas."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Area in sq km</th>\n","      <th>GVA</th>\n","      <th>HB_claimants</th>\n","      <th>Households in poverty</th>\n","      <th>Median house price</th>\n","      <th>Number of households</th>\n","      <th>Number of persons</th>\n","      <th>Total households assessed as owed a duty</th>\n","      <th>children_in_low_income</th>\n","      <th>council_tax_pensioners</th>\n","      <th>...</th>\n","      <th>imd_children</th>\n","      <th>imd_older_people</th>\n","      <th>number_of_children</th>\n","      <th>smi_loans_in_payment_households</th>\n","      <th>unemployment_rate_16_64</th>\n","      <th>ancestors</th>\n","      <th>parents</th>\n","      <th>children</th>\n","      <th>name</th>\n","      <th>type</th>\n","    </tr>\n","    <tr>\n","      <th>geography_code</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>E05000650</th>\n","      <td>6.556496</td>\n","      <td>82.047782</td>\n","      <td>374.0</td>\n","      <td>NaN</td>\n","      <td>196000.0</td>\n","      <td>5980.0</td>\n","      <td>14133.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3390.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[E08000001, E47000001, E12000002, E12999901]</td>\n","      <td>[E08000001]</td>\n","      <td>[]</td>\n","      <td>Astley Bridge</td>\n","      <td>WD22</td>\n","    </tr>\n","    <tr>\n","      <th>E05000651</th>\n","      <td>8.998946</td>\n","      <td>79.731727</td>\n","      <td>251.0</td>\n","      <td>NaN</td>\n","      <td>250000.0</td>\n","      <td>5300.0</td>\n","      <td>11331.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2530.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[E08000001, E47000001, E12000002, E12999901]</td>\n","      <td>[E08000001]</td>\n","      <td>[]</td>\n","      <td>Bradshaw</td>\n","      <td>WD22</td>\n","    </tr>\n","    <tr>\n","      <th>E05000652</th>\n","      <td>3.719582</td>\n","      <td>178.319099</td>\n","      <td>860.0</td>\n","      <td>NaN</td>\n","      <td>169975.0</td>\n","      <td>6810.0</td>\n","      <td>14078.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3722.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[E08000001, E47000001, E12000002, E12999901]</td>\n","      <td>[E08000001]</td>\n","      <td>[]</td>\n","      <td>Breightmet</td>\n","      <td>WD22</td>\n","    </tr>\n","    <tr>\n","      <th>E05000653</th>\n","      <td>7.340085</td>\n","      <td>110.950950</td>\n","      <td>175.0</td>\n","      <td>NaN</td>\n","      <td>253000.0</td>\n","      <td>5680.0</td>\n","      <td>13503.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2813.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[E08000001, E47000001, E12000002, E12999901]</td>\n","      <td>[E08000001]</td>\n","      <td>[]</td>\n","      <td>Bromley Cross</td>\n","      <td>WD22</td>\n","    </tr>\n","    <tr>\n","      <th>E05000654</th>\n","      <td>3.497711</td>\n","      <td>275.878141</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>120000.0</td>\n","      <td>6360.0</td>\n","      <td>16828.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4875.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[E08000001, E47000001, E12000002, E12999901]</td>\n","      <td>[E08000001]</td>\n","      <td>[]</td>\n","      <td>Crompton</td>\n","      <td>WD22</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>E47000003</th>\n","      <td>2023.378010</td>\n","      <td>60136.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1035190.0</td>\n","      <td>2349987.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>586078.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[E12000003, E12999901]</td>\n","      <td>[E12000003]</td>\n","      <td>[E08000032, E08000033, E08000034, E08000035, E...</td>\n","      <td>West Yorkshire</td>\n","      <td>CAUTH22</td>\n","    </tr>\n","    <tr>\n","      <th>E47000004</th>\n","      <td>723.925858</td>\n","      <td>35345.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>729960.0</td>\n","      <td>1551722.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>346827.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[E12000002, E12999901]</td>\n","      <td>[E12000002, E12000002]</td>\n","      <td>[E08000011, E08000012, E08000013, E08000014, E...</td>\n","      <td>Liverpool City Region</td>\n","      <td>CAUTH22</td>\n","    </tr>\n","    <tr>\n","      <th>E47000006</th>\n","      <td>792.415536</td>\n","      <td>14240.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>317080.0</td>\n","      <td>678173.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>159599.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[E12000001, E12999901]</td>\n","      <td>[E12000001]</td>\n","      <td>[E06000001, E06000002, E06000003, E06000004, E...</td>\n","      <td>Tees Valley</td>\n","      <td>CAUTH22</td>\n","    </tr>\n","    <tr>\n","      <th>E47000010</th>\n","      <td>2567.743895</td>\n","      <td>22517.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>550480.0</td>\n","      <td>1139626.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>247569.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[E12000001, E12999901]</td>\n","      <td>[E12000001]</td>\n","      <td>[E08000023, E08000024, E08000037, E06000047]</td>\n","      <td>North East</td>\n","      <td>CAUTH22</td>\n","    </tr>\n","    <tr>\n","      <th>E47000011</th>\n","      <td>5203.643991</td>\n","      <td>19726.000000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>395510.0</td>\n","      <td>828973.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>179841.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>[E12000001, E12999901]</td>\n","      <td>[E12000001]</td>\n","      <td>[E08000021, E08000022, E06000057]</td>\n","      <td>North of Tyne</td>\n","      <td>CAUTH22</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1651 rows × 24 columns</p>\n","</div>"],"text/plain":["                Area in sq km           GVA  HB_claimants   \n","geography_code                                              \n","E05000650            6.556496     82.047782         374.0  \\\n","E05000651            8.998946     79.731727         251.0   \n","E05000652            3.719582    178.319099         860.0   \n","E05000653            7.340085    110.950950         175.0   \n","E05000654            3.497711    275.878141           NaN   \n","...                       ...           ...           ...   \n","E47000003         2023.378010  60136.000000           NaN   \n","E47000004          723.925858  35345.000000           NaN   \n","E47000006          792.415536  14240.000000           NaN   \n","E47000010         2567.743895  22517.000000           NaN   \n","E47000011         5203.643991  19726.000000           NaN   \n","\n","                Households in poverty  Median house price   \n","geography_code                                              \n","E05000650                         NaN            196000.0  \\\n","E05000651                         NaN            250000.0   \n","E05000652                         NaN            169975.0   \n","E05000653                         NaN            253000.0   \n","E05000654                         NaN            120000.0   \n","...                               ...                 ...   \n","E47000003                         NaN                 NaN   \n","E47000004                         NaN                 NaN   \n","E47000006                         NaN                 NaN   \n","E47000010                         NaN                 NaN   \n","E47000011                         NaN                 NaN   \n","\n","                Number of households  Number of persons   \n","geography_code                                            \n","E05000650                     5980.0            14133.0  \\\n","E05000651                     5300.0            11331.0   \n","E05000652                     6810.0            14078.0   \n","E05000653                     5680.0            13503.0   \n","E05000654                     6360.0            16828.0   \n","...                              ...                ...   \n","E47000003                  1035190.0          2349987.0   \n","E47000004                   729960.0          1551722.0   \n","E47000006                   317080.0           678173.0   \n","E47000010                   550480.0          1139626.0   \n","E47000011                   395510.0           828973.0   \n","\n","                Total households assessed as owed a duty   \n","geography_code                                             \n","E05000650                                            NaN  \\\n","E05000651                                            NaN   \n","E05000652                                            NaN   \n","E05000653                                            NaN   \n","E05000654                                            NaN   \n","...                                                  ...   \n","E47000003                                            NaN   \n","E47000004                                            NaN   \n","E47000006                                            NaN   \n","E47000010                                            NaN   \n","E47000011                                            NaN   \n","\n","                children_in_low_income  council_tax_pensioners  ...   \n","geography_code                                                  ...   \n","E05000650                          NaN                     NaN  ...  \\\n","E05000651                          NaN                     NaN  ...   \n","E05000652                          NaN                     NaN  ...   \n","E05000653                          NaN                     NaN  ...   \n","E05000654                          NaN                     NaN  ...   \n","...                                ...                     ...  ...   \n","E47000003                          NaN                     NaN  ...   \n","E47000004                          NaN                     NaN  ...   \n","E47000006                          NaN                     NaN  ...   \n","E47000010                          NaN                     NaN  ...   \n","E47000011                          NaN                     NaN  ...   \n","\n","                imd_children  imd_older_people  number_of_children   \n","geography_code                                                       \n","E05000650                NaN               NaN              3390.0  \\\n","E05000651                NaN               NaN              2530.0   \n","E05000652                NaN               NaN              3722.0   \n","E05000653                NaN               NaN              2813.0   \n","E05000654                NaN               NaN              4875.0   \n","...                      ...               ...                 ...   \n","E47000003                NaN               NaN            586078.0   \n","E47000004                NaN               NaN            346827.0   \n","E47000006                NaN               NaN            159599.0   \n","E47000010                NaN               NaN            247569.0   \n","E47000011                NaN               NaN            179841.0   \n","\n","                smi_loans_in_payment_households  unemployment_rate_16_64   \n","geography_code                                                             \n","E05000650                                   NaN                      NaN  \\\n","E05000651                                   NaN                      NaN   \n","E05000652                                   NaN                      NaN   \n","E05000653                                   NaN                      NaN   \n","E05000654                                   NaN                      NaN   \n","...                                         ...                      ...   \n","E47000003                                   NaN                      NaN   \n","E47000004                                   NaN                      NaN   \n","E47000006                                   NaN                      NaN   \n","E47000010                                   NaN                      NaN   \n","E47000011                                   NaN                      NaN   \n","\n","                                                   ancestors   \n","geography_code                                                 \n","E05000650       [E08000001, E47000001, E12000002, E12999901]  \\\n","E05000651       [E08000001, E47000001, E12000002, E12999901]   \n","E05000652       [E08000001, E47000001, E12000002, E12999901]   \n","E05000653       [E08000001, E47000001, E12000002, E12999901]   \n","E05000654       [E08000001, E47000001, E12000002, E12999901]   \n","...                                                      ...   \n","E47000003                             [E12000003, E12999901]   \n","E47000004                             [E12000002, E12999901]   \n","E47000006                             [E12000001, E12999901]   \n","E47000010                             [E12000001, E12999901]   \n","E47000011                             [E12000001, E12999901]   \n","\n","                               parents   \n","geography_code                           \n","E05000650                  [E08000001]  \\\n","E05000651                  [E08000001]   \n","E05000652                  [E08000001]   \n","E05000653                  [E08000001]   \n","E05000654                  [E08000001]   \n","...                                ...   \n","E47000003                  [E12000003]   \n","E47000004       [E12000002, E12000002]   \n","E47000006                  [E12000001]   \n","E47000010                  [E12000001]   \n","E47000011                  [E12000001]   \n","\n","                                                         children   \n","geography_code                                                      \n","E05000650                                                      []  \\\n","E05000651                                                      []   \n","E05000652                                                      []   \n","E05000653                                                      []   \n","E05000654                                                      []   \n","...                                                           ...   \n","E47000003       [E08000032, E08000033, E08000034, E08000035, E...   \n","E47000004       [E08000011, E08000012, E08000013, E08000014, E...   \n","E47000006       [E06000001, E06000002, E06000003, E06000004, E...   \n","E47000010            [E08000023, E08000024, E08000037, E06000047]   \n","E47000011                       [E08000021, E08000022, E06000057]   \n","\n","                                 name     type  \n","geography_code                                  \n","E05000650               Astley Bridge     WD22  \n","E05000651                    Bradshaw     WD22  \n","E05000652                  Breightmet     WD22  \n","E05000653               Bromley Cross     WD22  \n","E05000654                    Crompton     WD22  \n","...                               ...      ...  \n","E47000003              West Yorkshire  CAUTH22  \n","E47000004       Liverpool City Region  CAUTH22  \n","E47000006                 Tees Valley  CAUTH22  \n","E47000010                  North East  CAUTH22  \n","E47000011               North of Tyne  CAUTH22  \n","\n","[1651 rows x 24 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["place_data = pd.concat([\n","    population_data,\n","    area_of_place,\n","    gva,\n","    households,\n","    council_tax_data,\n","    clif_data,\n","    number_of_children,\n","    savings,\n","    imd,\n","    house_prices,\n","    households_in_poverty,\n","    unemployment,\n","    economic_inactivity,\n","    imd_children,\n","    imd_older_people,\n","    housing_benefit,\n","    smi,\n","    homelessness\n","]).pivot(index='geography_code', columns='variable_name', values='value')\n","place_data = place_data.loc[place_data.index.isin(get_place_list())]\n","place_data = place_data.merge(get_place_data(), left_index=True, right_index=True, how='outer')\n","place_data.index.name = 'geography_code'\n","place_data"]},{"cell_type":"markdown","metadata":{},"source":["Create some additional metrics based on the data in place_data"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["place_data['Population density'] = place_data['Number of persons'] / place_data['Area in sq km']"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Finally, write the data to an interim parquet and json file for later usage."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"ename":"ImportError","evalue":"Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m os\u001b[39m.\u001b[39mmakedirs(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mDATA_DIR\u001b[39m}\u001b[39;00m\u001b[39m/interim/\u001b[39m\u001b[39m'\u001b[39m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m place_data\u001b[39m.\u001b[39;49mto_parquet(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mDATA_DIR\u001b[39m}\u001b[39;49;00m\u001b[39m/interim/place_data.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m place_data\u001b[39m.\u001b[39mreset_index()\u001b[39m.\u001b[39mto_json(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mDATA_DIR\u001b[39m}\u001b[39;00m\u001b[39m/interim/place_data.json\u001b[39m\u001b[39m\"\u001b[39m, orient\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\LukeStrange\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:2888\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[1;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   2801\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2802\u001b[0m \u001b[39mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[0;32m   2803\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2884\u001b[0m \u001b[39m>>> content = f.read()\u001b[39;00m\n\u001b[0;32m   2885\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2886\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparquet\u001b[39;00m \u001b[39mimport\u001b[39;00m to_parquet\n\u001b[1;32m-> 2888\u001b[0m \u001b[39mreturn\u001b[39;00m to_parquet(\n\u001b[0;32m   2889\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2890\u001b[0m     path,\n\u001b[0;32m   2891\u001b[0m     engine,\n\u001b[0;32m   2892\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   2893\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   2894\u001b[0m     partition_cols\u001b[39m=\u001b[39;49mpartition_cols,\n\u001b[0;32m   2895\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   2896\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   2897\u001b[0m )\n","File \u001b[1;32mc:\\Users\\LukeStrange\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:407\u001b[0m, in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(partition_cols, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    406\u001b[0m     partition_cols \u001b[39m=\u001b[39m [partition_cols]\n\u001b[1;32m--> 407\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[0;32m    409\u001b[0m path_or_buf: FilePath \u001b[39m|\u001b[39m WriteBuffer[\u001b[39mbytes\u001b[39m] \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO() \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[0;32m    411\u001b[0m impl\u001b[39m.\u001b[39mwrite(\n\u001b[0;32m    412\u001b[0m     df,\n\u001b[0;32m    413\u001b[0m     path_or_buf,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    419\u001b[0m )\n","File \u001b[1;32mc:\\Users\\LukeStrange\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:60\u001b[0m, in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m     58\u001b[0m             error_msgs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(err)\n\u001b[1;32m---> 60\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     61\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to find a usable engine; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     62\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtried using: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfastparquet\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     63\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA suitable version of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupport.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to import the above resulted in these errors:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     67\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00merror_msgs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m     )\n\u001b[0;32m     70\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     71\u001b[0m     \u001b[39mreturn\u001b[39;00m PyArrowImpl()\n","\u001b[1;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."]}],"source":["os.makedirs(f'{DATA_DIR}/interim/', exist_ok=True)\n","place_data.to_parquet(f'{DATA_DIR}/interim/place_data.parquet')\n","place_data.reset_index().to_json(f\"{DATA_DIR}/interim/place_data.json\", orient=\"records\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["geography_code\n","E05000650    196000.0\n","E05000651    250000.0\n","E05000652    169975.0\n","E05000653    253000.0\n","E05000654    120000.0\n","               ...   \n","E11000006    187000.0\n","E11000007    165000.0\n","E12000001    158000.0\n","E12000002    197000.0\n","E12000003    190000.0\n","Length: 1314, dtype: float64"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["house_prices = pd.read_csv(f'{DATA_DIR}/house-prices/house-prices.csv')\n","house_prices['date'] = pd.to_datetime(house_prices['date'])\n","#house_prices = house_prices.loc[house_prices.groupby(['geography_code'])['date'].idxmax()]\n","house_prices = house_prices.pivot(index='date', columns=\"geography_code\", values=\"value\")\n","house_prices.to_csv(os.path.join(SRC_DATA_DIR, 'time_series/house_prices.csv'))\n","house_prices.max()"]}],"metadata":{"kernelspec":{"display_name":"jrf-insight-VA15kXRI","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
